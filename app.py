import streamlit as st
import os
import faiss
import json
import numpy as np
import nest_asyncio
import re

from openai import OpenAI
from dotenv import load_dotenv

from utils.faiss_helpers import load_index_and_metadata
from utils.prompts import build_prompt, get_system_prompt
from utils.search import search_index

# âœ… Enable nested loops (required for Streamlit + OpenAI)
nest_asyncio.apply()

# âœ… Load environment variables
load_dotenv()

# âœ… Set up OpenAI client
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    organization=os.getenv("OPENAI_ORG_ID"),
    project=os.getenv("OPENAI_PROJECT_ID"),
)

# âœ… Load FAISS index and chunk metadata
index, metadata = load_index_and_metadata()

# âœ… Streamlit UI setup
st.set_page_config(page_title="Bratz GPT", layout="wide")
st.title("ðŸ’‹ Bratz GPT")
st.markdown("Whatâ€™s the vibe? Letâ€™s get into it.")

# ðŸ”€ Voice selector â€” single dropdown with clean labels
voice = st.selectbox(
    "Choose a Bratz voice:",
    ["Bratz Brand", "Cloe", "Jade", "Sasha", "Yasmin", "Raya"],
    index=0
)

# âœ… User input
query = st.text_input("Your question:")

# âœ… Process query
if query:
    results = search_index(query, index, metadata, top_k=5)
    if results:
        prompt = build_prompt(query, results, voice, voice)
        with st.spinner("Thinking like a Bratz queen..."):
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": get_system_prompt(voice, voice)
                    },
                    {"role": "user", "content": prompt}
                ]
            )
            raw_output = response.choices[0].message.content
            st.markdown("### Answer")
            st.write(raw_output)
    else:
        st.warning("No relevant context found.")